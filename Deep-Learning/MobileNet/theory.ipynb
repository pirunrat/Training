{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0048c84",
   "metadata": {},
   "source": [
    "# MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6056be9d",
   "metadata": {},
   "source": [
    "**Inroduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae3553",
   "metadata": {},
   "source": [
    "The original paper proposes an efficient network architecture and a set of two hyperparameters for building very small, low latency models dedicated to mobiles and embedded vision applications.\n",
    "The author mentioned that many papers on small networks focus on size but do not consider the speed, and this is the paintpoint that is addressed by MobileNet. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfca991",
   "metadata": {},
   "source": [
    "**Hilights**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Depth-wise separable convolutions : Replaces each standard conv with a depth-wise 3 × 3 followed by a 1 × 1 point-wise conv → ≈8-9 × fewer FLOPs & parameters while keeping accuracy high.\n",
    "\n",
    "2. Width multiplier (α) : Uniformly scales down every layer’s channel count (e.g., α = 0.75 or 0.5) to trade accuracy for smaller, faster models.\n",
    "\n",
    "3. Resolution multiplier (ρ) : Trains the same network at lower input resolutions (e.g., 192 × 192 or 160 × 160) for further compute savings.\n",
    "\n",
    "4. Resolution multiplier (ρ) : Trains the same network at lower input resolutions (e.g., 192 × 192 or 160 × 160) for further compute savings.\n",
    "\n",
    "5. Mobile-friendly design : ReLU6 activations and BatchNorm after every conv; integer-friendly channel counts (multiples of 8) for ARM/Qualcomm DSPs.\n",
    "\n",
    "6. Straightforward transfer learning : Performs well as a backbone for detection (SSD), segmentation (DeepLab), and face embeddings (FaceNet) with minimal extra tuning.\n",
    "\n",
    "7. Open-source TensorFlow implementation : Released with pretrained weights, accelerating adoption across Android, iOS, and embedded platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e79b93f",
   "metadata": {},
   "source": [
    "# Network Structure and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d107db26",
   "metadata": {},
   "source": [
    "The MobileNet is created based on depth-wise separable convolution except for the first layer which is a standard 3x3 convolution. In the architecture, layers include batchnormalization and RELU nonlinearlity while the last layer exclude the nonlinearlity since it's a fully connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edce2a8c",
   "metadata": {},
   "source": [
    "BY counting depth-wise and point-wise convolutions as separate layers, MobileNet has 28 layers as following:\n",
    "\n",
    "- 1 Standard convolution\n",
    "- 13 depth-wise + 13 point-wise convolutions\n",
    "- 1 fully-connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6354d1",
   "metadata": {},
   "source": [
    "Asynchronous gradient descent was used to train MobileNet models in TensorFlow with the RMSProp method. But the author uses fewer methods for regularization and data enhancement on small models than on large models because small models are less likely to overfit. During teaching, the author doesn't use side caps or label flattening. The author also limits the size of the tiny crops that are used for training in Inception so that there aren't too many picture errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cad8b",
   "metadata": {},
   "source": [
    "# Width and Resolution Multiplier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525e15b4",
   "metadata": {},
   "source": [
    "- Width factor (α) is a numeric value (less than 1) that decreases the number of channels in each convolutional layer in a way that doesn't change any other channels. This makes the network's \"width,\" parameters, and FLOPs smaller by about α².\n",
    "\n",
    "- Resolution multiplier (ρ) is a scalar value (< 1) that changes the size of the input picture and, by extension, every feature map. This lowers the spatial resolution and cuts the computation time by about ρ² without changing the layer definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5740b9",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c58b7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
