{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a876581",
   "metadata": {},
   "source": [
    "# TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacbedac",
   "metadata": {},
   "source": [
    "The author proposes an end-to-end transformer-based OCR model for text recognition with pre-trained CV and NLP models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463d960a",
   "metadata": {},
   "source": [
    "One benefit of TrOCR is that it:\n",
    "\n",
    "- TrOCR uses image transformer and text transformer models that have already been trained. These models use large amounts of unstructured data to understand images and model language, so they don't need an external language model.\n",
    "\n",
    "- TrOCR doesn't need any inductive biases or convolutional networks, which makes the model very simple to set up and keep up to date.\n",
    "- Based on the results of the experiment on the OCR benchmark dataset, TrOCR gets top-notch results on printed, handwritten, and scene text image datasets with no complicated pre- or post-processing steps. It can also be easily expanded to recognize text in multiple languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5097445",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c7950",
   "metadata": {},
   "source": [
    "For the architecture, the authors adopt the vanilla transformer encoder-decoder structure in TrOCR. The encoder is designed to obtain the representation of the input image patches and the decoder is aimed at generating the sequence of words guided by the visual features and previous predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0b72c9",
   "metadata": {},
   "source": [
    "**Encoder** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f208074",
   "metadata": {},
   "source": [
    "After receiving an input image, the encoder resizes it to a predetermined size. Since the encoder does not process raw images, the input picture must be converted into tokens. After splitting the input picture into PxP patches, the encoder flattens the patches to create vectors, which are then projected onto a linear transformation to create embedding vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f319591",
   "metadata": {},
   "source": [
    "According to the author, they retain the unique tokens \"[CLS],\" which are used for image classification tasks. The \"[CLS]\" represents the entire image by compiling all of the data from all of the patch embeddings. Additionally, when they use DeiT pre-trained models for encoder initialization, they retain the distillation token in the input sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaced82",
   "metadata": {},
   "source": [
    "what separates TrOCR from traditional CNN-like networks is that it has no inductive biases and process the image as a sequence of patches, which enables the model to pay attention to different patches and the whole image easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35dfe86",
   "metadata": {},
   "source": [
    "**Decoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc9fa64",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
